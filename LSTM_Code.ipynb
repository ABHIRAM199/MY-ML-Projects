{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30761,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "LSTM Code",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ABHIRAM199/MY-ML-Projects/blob/main/LSTM_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-09-12T11:48:06.880664Z",
          "iopub.execute_input": "2024-09-12T11:48:06.88157Z",
          "iopub.status.idle": "2024-09-12T11:48:07.326008Z",
          "shell.execute_reply.started": "2024-09-12T11:48:06.881524Z",
          "shell.execute_reply": "2024-09-12T11:48:07.324781Z"
        },
        "trusted": true,
        "id": "0Mth93jcdF5N"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# Generate a sequence of numbers\n",
        "sequence = np.array([i for i in range(1, 101)])\n",
        "\n",
        "# Prepare the data: X = previous 5 numbers, y = next number\n",
        "def create_dataset(sequence, time_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(sequence) - time_steps):\n",
        "        X.append(sequence[i:i + time_steps])\n",
        "        y.append(sequence[i + time_steps])\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T11:48:40.806244Z",
          "iopub.execute_input": "2024-09-12T11:48:40.807697Z",
          "iopub.status.idle": "2024-09-12T11:48:54.475152Z",
          "shell.execute_reply.started": "2024-09-12T11:48:40.807646Z",
          "shell.execute_reply": "2024-09-12T11:48:54.473987Z"
        },
        "trusted": true,
        "id": "hPMaQw1IdF5O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define time_steps\n",
        "time_steps = 5\n",
        "\n",
        "# Create dataset\n",
        "X, y = create_dataset(sequence, time_steps)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T11:49:22.221013Z",
          "iopub.execute_input": "2024-09-12T11:49:22.221779Z",
          "iopub.status.idle": "2024-09-12T11:49:22.227823Z",
          "shell.execute_reply.started": "2024-09-12T11:49:22.221733Z",
          "shell.execute_reply": "2024-09-12T11:49:22.226455Z"
        },
        "trusted": true,
        "id": "5NR5KnP9dF5O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T11:49:26.451882Z",
          "iopub.execute_input": "2024-09-12T11:49:26.452285Z",
          "iopub.status.idle": "2024-09-12T11:49:26.464493Z",
          "shell.execute_reply.started": "2024-09-12T11:49:26.452246Z",
          "shell.execute_reply": "2024-09-12T11:49:26.463378Z"
        },
        "trusted": true,
        "id": "V28t5NeYdF5O",
        "outputId": "6f3401eb-7c10-4114-ac98-1ab48144ebbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  2,  3,  4,  5],\n",
              "       [ 2,  3,  4,  5,  6],\n",
              "       [ 3,  4,  5,  6,  7],\n",
              "       [ 4,  5,  6,  7,  8],\n",
              "       [ 5,  6,  7,  8,  9],\n",
              "       [ 6,  7,  8,  9, 10],\n",
              "       [ 7,  8,  9, 10, 11],\n",
              "       [ 8,  9, 10, 11, 12],\n",
              "       [ 9, 10, 11, 12, 13],\n",
              "       [10, 11, 12, 13, 14],\n",
              "       [11, 12, 13, 14, 15],\n",
              "       [12, 13, 14, 15, 16],\n",
              "       [13, 14, 15, 16, 17],\n",
              "       [14, 15, 16, 17, 18],\n",
              "       [15, 16, 17, 18, 19],\n",
              "       [16, 17, 18, 19, 20],\n",
              "       [17, 18, 19, 20, 21],\n",
              "       [18, 19, 20, 21, 22],\n",
              "       [19, 20, 21, 22, 23],\n",
              "       [20, 21, 22, 23, 24],\n",
              "       [21, 22, 23, 24, 25],\n",
              "       [22, 23, 24, 25, 26],\n",
              "       [23, 24, 25, 26, 27],\n",
              "       [24, 25, 26, 27, 28],\n",
              "       [25, 26, 27, 28, 29],\n",
              "       [26, 27, 28, 29, 30],\n",
              "       [27, 28, 29, 30, 31],\n",
              "       [28, 29, 30, 31, 32],\n",
              "       [29, 30, 31, 32, 33],\n",
              "       [30, 31, 32, 33, 34],\n",
              "       [31, 32, 33, 34, 35],\n",
              "       [32, 33, 34, 35, 36],\n",
              "       [33, 34, 35, 36, 37],\n",
              "       [34, 35, 36, 37, 38],\n",
              "       [35, 36, 37, 38, 39],\n",
              "       [36, 37, 38, 39, 40],\n",
              "       [37, 38, 39, 40, 41],\n",
              "       [38, 39, 40, 41, 42],\n",
              "       [39, 40, 41, 42, 43],\n",
              "       [40, 41, 42, 43, 44],\n",
              "       [41, 42, 43, 44, 45],\n",
              "       [42, 43, 44, 45, 46],\n",
              "       [43, 44, 45, 46, 47],\n",
              "       [44, 45, 46, 47, 48],\n",
              "       [45, 46, 47, 48, 49],\n",
              "       [46, 47, 48, 49, 50],\n",
              "       [47, 48, 49, 50, 51],\n",
              "       [48, 49, 50, 51, 52],\n",
              "       [49, 50, 51, 52, 53],\n",
              "       [50, 51, 52, 53, 54],\n",
              "       [51, 52, 53, 54, 55],\n",
              "       [52, 53, 54, 55, 56],\n",
              "       [53, 54, 55, 56, 57],\n",
              "       [54, 55, 56, 57, 58],\n",
              "       [55, 56, 57, 58, 59],\n",
              "       [56, 57, 58, 59, 60],\n",
              "       [57, 58, 59, 60, 61],\n",
              "       [58, 59, 60, 61, 62],\n",
              "       [59, 60, 61, 62, 63],\n",
              "       [60, 61, 62, 63, 64],\n",
              "       [61, 62, 63, 64, 65],\n",
              "       [62, 63, 64, 65, 66],\n",
              "       [63, 64, 65, 66, 67],\n",
              "       [64, 65, 66, 67, 68],\n",
              "       [65, 66, 67, 68, 69],\n",
              "       [66, 67, 68, 69, 70],\n",
              "       [67, 68, 69, 70, 71],\n",
              "       [68, 69, 70, 71, 72],\n",
              "       [69, 70, 71, 72, 73],\n",
              "       [70, 71, 72, 73, 74],\n",
              "       [71, 72, 73, 74, 75],\n",
              "       [72, 73, 74, 75, 76],\n",
              "       [73, 74, 75, 76, 77],\n",
              "       [74, 75, 76, 77, 78],\n",
              "       [75, 76, 77, 78, 79],\n",
              "       [76, 77, 78, 79, 80],\n",
              "       [77, 78, 79, 80, 81],\n",
              "       [78, 79, 80, 81, 82],\n",
              "       [79, 80, 81, 82, 83],\n",
              "       [80, 81, 82, 83, 84],\n",
              "       [81, 82, 83, 84, 85],\n",
              "       [82, 83, 84, 85, 86],\n",
              "       [83, 84, 85, 86, 87],\n",
              "       [84, 85, 86, 87, 88],\n",
              "       [85, 86, 87, 88, 89],\n",
              "       [86, 87, 88, 89, 90],\n",
              "       [87, 88, 89, 90, 91],\n",
              "       [88, 89, 90, 91, 92],\n",
              "       [89, 90, 91, 92, 93],\n",
              "       [90, 91, 92, 93, 94],\n",
              "       [91, 92, 93, 94, 95],\n",
              "       [92, 93, 94, 95, 96],\n",
              "       [93, 94, 95, 96, 97],\n",
              "       [94, 95, 96, 97, 98],\n",
              "       [95, 96, 97, 98, 99]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape X for LSTM input: [samples, time_steps, features]\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', input_shape=(time_steps, 1)))\n",
        "model.add(Dense(1))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics = ['mse'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X, y, epochs=200, verbose=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T11:52:53.998387Z",
          "iopub.execute_input": "2024-09-12T11:52:53.998916Z",
          "iopub.status.idle": "2024-09-12T11:53:02.315975Z",
          "shell.execute_reply.started": "2024-09-12T11:52:53.998873Z",
          "shell.execute_reply": "2024-09-12T11:53:02.314725Z"
        },
        "trusted": true,
        "id": "HQWS2LJXdF5O",
        "outputId": "2520ef15-c90a-44ac-f786-8c97914ecbf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "test_input = np.array([96, 97, 98, 99, 100]).reshape((1, time_steps, 1))\n",
        "predicted = model.predict(test_input, verbose=0)\n",
        "\n",
        "print(f'Predicted next number in the sequence: {predicted[0][0]}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T11:53:06.061804Z",
          "iopub.execute_input": "2024-09-12T11:53:06.062983Z",
          "iopub.status.idle": "2024-09-12T11:53:06.291277Z",
          "shell.execute_reply.started": "2024-09-12T11:53:06.062925Z",
          "shell.execute_reply": "2024-09-12T11:53:06.290144Z"
        },
        "trusted": true,
        "id": "Z64VoHrVdF5P",
        "outputId": "ccc648b9-4b94-4b2f-fb20-fd3a20dfe868",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next number in the sequence: 101.04672241210938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Example text data\n",
        "text = \"\"\"\n",
        "In the field of Natural Language Processing (NLP), predicting the next word in a sentence is a key task that relies heavily on machine learning models.\n",
        "These models, particularly Recurrent Neural Networks (RNNs) and Transformers, learn patterns in the structure of language by analyzing vast amounts of\n",
        "text data. The model is trained to understand the context and the relationship between words, allowing it to generate the next most likely word based\n",
        "on the given input. One popular architecture used for this task is the GPT (Generative Pretrained Transformer), which is a type of Transformer model.\n",
        "GPT-based models, such as GPT-3 and GPT-4, have been trained on billions of parameters and have a deep understanding of syntax, semantics, and even\n",
        "common phrases, allowing them to predict the next word with remarkable accuracy.For example, given the sentence \"The cat sat on the\", a word prediction\n",
        "model would predict the next word as \"mat,\" since it has learned that \"cat sat on the mat\" is a common phrase in the training data.\n",
        "The process works by encoding the input text into a vector of numbers, which captures the semantic and syntactic information. The model then decodes\n",
        "this information to predict the most probable next word, considering both the immediate context and larger sentence structures.\n",
        "By continuously fine-tuning these models and feeding them more diverse datasets, the accuracy and creativity of word prediction in NLP tasks have\n",
        "improved dramatically.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T12:06:31.608111Z",
          "iopub.execute_input": "2024-09-12T12:06:31.609266Z",
          "iopub.status.idle": "2024-09-12T12:06:31.619616Z",
          "shell.execute_reply.started": "2024-09-12T12:06:31.609217Z",
          "shell.execute_reply": "2024-09-12T12:06:31.618311Z"
        },
        "trusted": true,
        "id": "sUyGmGlBdF5P"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to sequences of integers\n",
        "input_sequences = []\n",
        "for line in text.split('.'):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences to the same length\n",
        "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T12:06:45.64405Z",
          "iopub.execute_input": "2024-09-12T12:06:45.644824Z",
          "iopub.status.idle": "2024-09-12T12:06:45.652823Z",
          "shell.execute_reply.started": "2024-09-12T12:06:45.644776Z",
          "shell.execute_reply": "2024-09-12T12:06:45.651605Z"
        },
        "trusted": true,
        "id": "SPK3D2erdF5P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into input (X) and output (y)\n",
        "X, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, verbose=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T12:06:52.18645Z",
          "iopub.execute_input": "2024-09-12T12:06:52.186895Z",
          "iopub.status.idle": "2024-09-12T12:06:58.076811Z",
          "shell.execute_reply.started": "2024-09-12T12:06:52.186848Z",
          "shell.execute_reply": "2024-09-12T12:06:58.07568Z"
        },
        "trusted": true,
        "id": "tJbNwR7kdF5P",
        "outputId": "c5d6c7d1-d225-4b82-e4d0-35befa9dd2d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 - 3s - 323ms/step - accuracy: 0.0517 - loss: 4.8572\n",
            "Epoch 2/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.0862 - loss: 4.8218\n",
            "Epoch 3/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.0862 - loss: 4.6888\n",
            "Epoch 4/100\n",
            "8/8 - 0s - 37ms/step - accuracy: 0.0862 - loss: 4.5907\n",
            "Epoch 5/100\n",
            "8/8 - 0s - 38ms/step - accuracy: 0.0862 - loss: 4.5530\n",
            "Epoch 6/100\n",
            "8/8 - 0s - 33ms/step - accuracy: 0.0862 - loss: 4.5259\n",
            "Epoch 7/100\n",
            "8/8 - 0s - 35ms/step - accuracy: 0.0862 - loss: 4.5021\n",
            "Epoch 8/100\n",
            "8/8 - 0s - 36ms/step - accuracy: 0.0862 - loss: 4.4867\n",
            "Epoch 9/100\n",
            "8/8 - 0s - 39ms/step - accuracy: 0.0862 - loss: 4.4611\n",
            "Epoch 10/100\n",
            "8/8 - 0s - 35ms/step - accuracy: 0.0862 - loss: 4.4305\n",
            "Epoch 11/100\n",
            "8/8 - 0s - 51ms/step - accuracy: 0.0862 - loss: 4.4056\n",
            "Epoch 12/100\n",
            "8/8 - 0s - 51ms/step - accuracy: 0.0862 - loss: 4.3608\n",
            "Epoch 13/100\n",
            "8/8 - 1s - 76ms/step - accuracy: 0.0862 - loss: 4.3275\n",
            "Epoch 14/100\n",
            "8/8 - 1s - 77ms/step - accuracy: 0.0948 - loss: 4.2750\n",
            "Epoch 15/100\n",
            "8/8 - 0s - 50ms/step - accuracy: 0.0862 - loss: 4.2424\n",
            "Epoch 16/100\n",
            "8/8 - 0s - 53ms/step - accuracy: 0.0948 - loss: 4.1902\n",
            "Epoch 17/100\n",
            "8/8 - 0s - 55ms/step - accuracy: 0.0948 - loss: 4.1309\n",
            "Epoch 18/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.0991 - loss: 4.0787\n",
            "Epoch 19/100\n",
            "8/8 - 0s - 32ms/step - accuracy: 0.0991 - loss: 4.0224\n",
            "Epoch 20/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.1164 - loss: 3.9456\n",
            "Epoch 21/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.1336 - loss: 3.8904\n",
            "Epoch 22/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.1336 - loss: 3.8222\n",
            "Epoch 23/100\n",
            "8/8 - 0s - 40ms/step - accuracy: 0.1422 - loss: 3.7490\n",
            "Epoch 24/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.1466 - loss: 3.6795\n",
            "Epoch 25/100\n",
            "8/8 - 0s - 29ms/step - accuracy: 0.1638 - loss: 3.6345\n",
            "Epoch 26/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.1595 - loss: 3.5446\n",
            "Epoch 27/100\n",
            "8/8 - 0s - 32ms/step - accuracy: 0.1724 - loss: 3.4771\n",
            "Epoch 28/100\n",
            "8/8 - 0s - 36ms/step - accuracy: 0.2026 - loss: 3.4088\n",
            "Epoch 29/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.2155 - loss: 3.3386\n",
            "Epoch 30/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.2112 - loss: 3.2845\n",
            "Epoch 31/100\n",
            "8/8 - 0s - 41ms/step - accuracy: 0.2414 - loss: 3.2097\n",
            "Epoch 32/100\n",
            "8/8 - 0s - 32ms/step - accuracy: 0.2284 - loss: 3.1396\n",
            "Epoch 33/100\n",
            "8/8 - 0s - 38ms/step - accuracy: 0.2414 - loss: 3.0661\n",
            "Epoch 34/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.2543 - loss: 3.0012\n",
            "Epoch 35/100\n",
            "8/8 - 0s - 37ms/step - accuracy: 0.2672 - loss: 2.9288\n",
            "Epoch 36/100\n",
            "8/8 - 0s - 36ms/step - accuracy: 0.2931 - loss: 2.8589\n",
            "Epoch 37/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.3147 - loss: 2.7794\n",
            "Epoch 38/100\n",
            "8/8 - 0s - 32ms/step - accuracy: 0.3233 - loss: 2.7281\n",
            "Epoch 39/100\n",
            "8/8 - 0s - 39ms/step - accuracy: 0.3362 - loss: 2.6537\n",
            "Epoch 40/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.3491 - loss: 2.5922\n",
            "Epoch 41/100\n",
            "8/8 - 0s - 38ms/step - accuracy: 0.3707 - loss: 2.5310\n",
            "Epoch 42/100\n",
            "8/8 - 0s - 40ms/step - accuracy: 0.4353 - loss: 2.4851\n",
            "Epoch 43/100\n",
            "8/8 - 0s - 33ms/step - accuracy: 0.4181 - loss: 2.4134\n",
            "Epoch 44/100\n",
            "8/8 - 0s - 32ms/step - accuracy: 0.4871 - loss: 2.3412\n",
            "Epoch 45/100\n",
            "8/8 - 0s - 39ms/step - accuracy: 0.4698 - loss: 2.2742\n",
            "Epoch 46/100\n",
            "8/8 - 0s - 33ms/step - accuracy: 0.5000 - loss: 2.2105\n",
            "Epoch 47/100\n",
            "8/8 - 0s - 39ms/step - accuracy: 0.4914 - loss: 2.1568\n",
            "Epoch 48/100\n",
            "8/8 - 0s - 37ms/step - accuracy: 0.5259 - loss: 2.0958\n",
            "Epoch 49/100\n",
            "8/8 - 0s - 39ms/step - accuracy: 0.5216 - loss: 2.0349\n",
            "Epoch 50/100\n",
            "8/8 - 0s - 36ms/step - accuracy: 0.5733 - loss: 1.9908\n",
            "Epoch 51/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.5948 - loss: 1.9287\n",
            "Epoch 52/100\n",
            "8/8 - 0s - 32ms/step - accuracy: 0.6078 - loss: 1.8869\n",
            "Epoch 53/100\n",
            "8/8 - 0s - 45ms/step - accuracy: 0.6250 - loss: 1.8313\n",
            "Epoch 54/100\n",
            "8/8 - 0s - 51ms/step - accuracy: 0.6595 - loss: 1.7789\n",
            "Epoch 55/100\n",
            "8/8 - 1s - 77ms/step - accuracy: 0.6638 - loss: 1.7285\n",
            "Epoch 56/100\n",
            "8/8 - 0s - 51ms/step - accuracy: 0.6638 - loss: 1.6816\n",
            "Epoch 57/100\n",
            "8/8 - 1s - 77ms/step - accuracy: 0.6810 - loss: 1.6300\n",
            "Epoch 58/100\n",
            "8/8 - 0s - 52ms/step - accuracy: 0.7328 - loss: 1.5888\n",
            "Epoch 59/100\n",
            "8/8 - 0s - 59ms/step - accuracy: 0.7414 - loss: 1.5455\n",
            "Epoch 60/100\n",
            "8/8 - 0s - 36ms/step - accuracy: 0.7629 - loss: 1.5053\n",
            "Epoch 61/100\n",
            "8/8 - 0s - 36ms/step - accuracy: 0.7672 - loss: 1.4537\n",
            "Epoch 62/100\n",
            "8/8 - 0s - 39ms/step - accuracy: 0.7802 - loss: 1.4124\n",
            "Epoch 63/100\n",
            "8/8 - 0s - 36ms/step - accuracy: 0.8060 - loss: 1.3708\n",
            "Epoch 64/100\n",
            "8/8 - 0s - 37ms/step - accuracy: 0.8103 - loss: 1.3273\n",
            "Epoch 65/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.8578 - loss: 1.2925\n",
            "Epoch 66/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.8491 - loss: 1.2543\n",
            "Epoch 67/100\n",
            "8/8 - 0s - 36ms/step - accuracy: 0.8793 - loss: 1.2216\n",
            "Epoch 68/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.8793 - loss: 1.1919\n",
            "Epoch 69/100\n",
            "8/8 - 0s - 32ms/step - accuracy: 0.8793 - loss: 1.1540\n",
            "Epoch 70/100\n",
            "8/8 - 0s - 37ms/step - accuracy: 0.8879 - loss: 1.1249\n",
            "Epoch 71/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.9138 - loss: 1.0944\n",
            "Epoch 72/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.9224 - loss: 1.0542\n",
            "Epoch 73/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.9310 - loss: 1.0197\n",
            "Epoch 74/100\n",
            "8/8 - 0s - 32ms/step - accuracy: 0.9267 - loss: 0.9887\n",
            "Epoch 75/100\n",
            "8/8 - 0s - 36ms/step - accuracy: 0.9310 - loss: 0.9612\n",
            "Epoch 76/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.9440 - loss: 0.9392\n",
            "Epoch 77/100\n",
            "8/8 - 0s - 36ms/step - accuracy: 0.9397 - loss: 0.9134\n",
            "Epoch 78/100\n",
            "8/8 - 0s - 32ms/step - accuracy: 0.9569 - loss: 0.8845\n",
            "Epoch 79/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.9569 - loss: 0.8543\n",
            "Epoch 80/100\n",
            "8/8 - 0s - 38ms/step - accuracy: 0.9612 - loss: 0.8295\n",
            "Epoch 81/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.9612 - loss: 0.8084\n",
            "Epoch 82/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.9655 - loss: 0.7836\n",
            "Epoch 83/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.9655 - loss: 0.7637\n",
            "Epoch 84/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.9698 - loss: 0.7391\n",
            "Epoch 85/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.9698 - loss: 0.7187\n",
            "Epoch 86/100\n",
            "8/8 - 0s - 32ms/step - accuracy: 0.9741 - loss: 0.7022\n",
            "Epoch 87/100\n",
            "8/8 - 0s - 36ms/step - accuracy: 0.9698 - loss: 0.6899\n",
            "Epoch 88/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.9698 - loss: 0.6658\n",
            "Epoch 89/100\n",
            "8/8 - 0s - 38ms/step - accuracy: 0.9698 - loss: 0.6535\n",
            "Epoch 90/100\n",
            "8/8 - 0s - 35ms/step - accuracy: 0.9741 - loss: 0.6440\n",
            "Epoch 91/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.9784 - loss: 0.6186\n",
            "Epoch 92/100\n",
            "8/8 - 0s - 36ms/step - accuracy: 0.9828 - loss: 0.5993\n",
            "Epoch 93/100\n",
            "8/8 - 0s - 31ms/step - accuracy: 0.9784 - loss: 0.5898\n",
            "Epoch 94/100\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.9828 - loss: 0.5681\n",
            "Epoch 95/100\n",
            "8/8 - 0s - 40ms/step - accuracy: 0.9828 - loss: 0.5488\n",
            "Epoch 96/100\n",
            "8/8 - 0s - 50ms/step - accuracy: 0.9871 - loss: 0.5303\n",
            "Epoch 97/100\n",
            "8/8 - 0s - 52ms/step - accuracy: 0.9871 - loss: 0.5151\n",
            "Epoch 98/100\n",
            "8/8 - 1s - 75ms/step - accuracy: 0.9871 - loss: 0.5058\n",
            "Epoch 99/100\n",
            "8/8 - 1s - 78ms/step - accuracy: 0.9871 - loss: 0.4945\n",
            "Epoch 100/100\n",
            "8/8 - 1s - 80ms/step - accuracy: 0.9914 - loss: 0.4784\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e6daa4a6530>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict the next word\n",
        "def predict_next_word(model, tokenizer, text_input, max_sequence_len):\n",
        "    token_list = tokenizer.texts_to_sequences([text_input])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicted, axis=-1)\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_word_index:\n",
        "            return word\n",
        "\n",
        "# Test the model\n",
        "test_text = \"prediction\"\n",
        "predicted_word = predict_next_word(model, tokenizer, test_text, max_sequence_len)\n",
        "print(f'Predicted next word: {predicted_word}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T12:07:06.635875Z",
          "iopub.execute_input": "2024-09-12T12:07:06.636284Z",
          "iopub.status.idle": "2024-09-12T12:07:06.881882Z",
          "shell.execute_reply.started": "2024-09-12T12:07:06.636245Z",
          "shell.execute_reply": "2024-09-12T12:07:06.880658Z"
        },
        "trusted": true,
        "id": "UwL5dOz8dF5P",
        "outputId": "d577f591-9b58-440c-aafc-52b97a466c6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next word: model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Sample text data\n",
        "text = \"\"\"Success is not final, failure is not fatal: It is the courage to continue that counts.\" – Winston Churchill\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Convert text into sequences of tokens\n",
        "input_sequences = []\n",
        "for line in text.split(\".\"):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences to ensure they are of the same length\n",
        "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split into input (X) and output (y)\n",
        "X, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01), metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, verbose=1)\n",
        "\n",
        "# Function to predict the next word"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T12:08:39.231139Z",
          "iopub.execute_input": "2024-09-12T12:08:39.23172Z",
          "iopub.status.idle": "2024-09-12T12:08:45.863678Z",
          "shell.execute_reply.started": "2024-09-12T12:08:39.231678Z",
          "shell.execute_reply": "2024-09-12T12:08:45.862469Z"
        },
        "trusted": true,
        "id": "5n79OIfGdF5Q",
        "outputId": "f4f7fb79-5c96-4d58-f372-f71d7a974d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.1765 - loss: 2.8300\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.1765 - loss: 2.7728\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.1765 - loss: 2.5682\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.1765 - loss: 2.7277\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2941 - loss: 2.5147\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.2353 - loss: 2.4320\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1765 - loss: 2.3341\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.1765 - loss: 2.2502\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.2941 - loss: 2.0876\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2353 - loss: 2.0066\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2353 - loss: 1.8802\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4118 - loss: 1.7583\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3529 - loss: 1.6730\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5294 - loss: 1.5415\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4706 - loss: 1.4440\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.3529 - loss: 1.4066\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5882 - loss: 1.2816\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5882 - loss: 1.1711\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6471 - loss: 1.1613\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5294 - loss: 1.1286\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7647 - loss: 0.9801\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6471 - loss: 0.9794\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5294 - loss: 0.9698\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7059 - loss: 0.8352\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7059 - loss: 0.8369\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7647 - loss: 0.7719\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7647 - loss: 0.7393\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8824 - loss: 0.7090\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8235 - loss: 0.6582\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8235 - loss: 0.6434\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8824 - loss: 0.5838\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9412 - loss: 0.5766\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9412 - loss: 0.5197\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9412 - loss: 0.5108\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.4609\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9412 - loss: 0.4456\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.4052\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.3863\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.3466\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.3260\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.2880\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.2702\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.2337\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2182\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.1879\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.1693\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.1494\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1284\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.1149\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0972\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0852\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0749\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0637\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0566\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0492\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0421\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0377\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 0.0334\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0288\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0257\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0234\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0210\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0186\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0169\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0156\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0143\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0131\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0120\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0112\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0105\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.0098\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0092\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0086\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0081\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0077\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0073\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0070\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0066\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0063\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0060\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0058\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0056\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0054\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0052\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.0050\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0049\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0047\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0046\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0044\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0043\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0042\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0041\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0040\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0039\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0038\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0037\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0036\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0036\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0035\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0034\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e6db88e9870>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, tokenizer, text_sequence, max_sequence_len):\n",
        "    token_list = tokenizer.texts_to_sequences([text_sequence])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "    return tokenizer.index_word[predicted[0]]\n",
        "\n",
        "# Test the model to predict the next word\n",
        "seed_text = \"Winston\"\n",
        "next_word = predict_next_word(model, tokenizer, seed_text, max_sequence_len)\n",
        "print(f\"Predicted next word: {next_word}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T12:08:51.105033Z",
          "iopub.execute_input": "2024-09-12T12:08:51.106111Z",
          "iopub.status.idle": "2024-09-12T12:08:51.346963Z",
          "shell.execute_reply.started": "2024-09-12T12:08:51.106059Z",
          "shell.execute_reply": "2024-09-12T12:08:51.34588Z"
        },
        "trusted": true,
        "id": "YNxP8D1BdF5Q",
        "outputId": "46a42a09-a3be-491f-e1db-322826fbef7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
            "Predicted next word: churchill\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense\n",
        "\n",
        "# Generate a sequence of numbers\n",
        "sequence = np.array([i for i in range(1, 101)])\n",
        "\n",
        "# Prepare the data: X = previous 5 numbers, y = next number\n",
        "def create_dataset(sequence, time_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(sequence) - time_steps):\n",
        "        X.append(sequence[i:i + time_steps])\n",
        "        y.append(sequence[i + time_steps])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Define time_steps\n",
        "time_steps = 5\n",
        "\n",
        "# Create dataset\n",
        "X, y = create_dataset(sequence, time_steps)\n",
        "\n",
        "# Reshape X for BiLSTM input: [samples, time_steps, features]\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Build the BiLSTM model\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(time_steps, 1)))\n",
        "model.add(Dense(1))  # Output layer to predict next number\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=200, verbose=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T12:14:56.805474Z",
          "iopub.execute_input": "2024-09-12T12:14:56.805954Z",
          "iopub.status.idle": "2024-09-12T12:15:06.456738Z",
          "shell.execute_reply.started": "2024-09-12T12:14:56.805914Z",
          "shell.execute_reply": "2024-09-12T12:15:06.455551Z"
        },
        "trusted": true,
        "id": "HAyudLYHdF5Q",
        "outputId": "b6f0a2f7-3185-4dc8-f5ac-747138a2071b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e6db8a7b400>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = np.array([96, 97, 98, 99, 100]).reshape((1, time_steps, 1))\n",
        "predicted = model.predict(test_input, verbose=0)\n",
        "\n",
        "print(f'Predicted next number in the sequence: {predicted[0][0]}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T12:15:22.356524Z",
          "iopub.execute_input": "2024-09-12T12:15:22.356932Z",
          "iopub.status.idle": "2024-09-12T12:15:22.701633Z",
          "shell.execute_reply.started": "2024-09-12T12:15:22.356894Z",
          "shell.execute_reply": "2024-09-12T12:15:22.700486Z"
        },
        "trusted": true,
        "id": "wic9rrhwdF5Q",
        "outputId": "cd24c9e2-0921-4c42-da9c-b1f9fa606a6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next number in the sequence: 101.06700134277344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "\n",
        "# Example text data\n",
        "text = \"\"\"\n",
        "In the future, AI-powered robots in hospitals could autonomously diagnose patients, assist with surgeries, and provide personalized care.\n",
        "Using real-time data analysis and machine learning, these robots would adapt to patient needs, optimize treatment plans, and collaborate with\n",
        "medical staff, transforming healthcare efficiency and precision.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1  # Add 1 for padding\n",
        "\n",
        "# Convert text to sequences of integers\n",
        "input_sequences = []\n",
        "for line in text.split('.'):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences to the same length\n",
        "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "\n",
        "# Split data into input (X) and output (y)\n",
        "X, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# Build the BiLSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))  # Embedding layer\n",
        "model.add(Bidirectional(LSTM(100)))  # Bidirectional LSTM layer\n",
        "model.add(Dense(total_words, activation='softmax'))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, verbose=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T12:17:48.945604Z",
          "iopub.execute_input": "2024-09-12T12:17:48.946501Z",
          "iopub.status.idle": "2024-09-12T12:17:56.564269Z",
          "shell.execute_reply.started": "2024-09-12T12:17:48.946456Z",
          "shell.execute_reply": "2024-09-12T12:17:56.563182Z"
        },
        "trusted": true,
        "id": "0y8xp-T8dF5Q",
        "outputId": "1dfc72df-fb46-4687-e3da-6e40f7fe7948",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 - 4s - 2s/step - accuracy: 0.0222 - loss: 3.7411\n",
            "Epoch 2/100\n",
            "2/2 - 0s - 79ms/step - accuracy: 0.0667 - loss: 3.7303\n",
            "Epoch 3/100\n",
            "2/2 - 0s - 62ms/step - accuracy: 0.0889 - loss: 3.7224\n",
            "Epoch 4/100\n",
            "2/2 - 0s - 68ms/step - accuracy: 0.0889 - loss: 3.7150\n",
            "Epoch 5/100\n",
            "2/2 - 0s - 68ms/step - accuracy: 0.0889 - loss: 3.7061\n",
            "Epoch 6/100\n",
            "2/2 - 0s - 70ms/step - accuracy: 0.0889 - loss: 3.6962\n",
            "Epoch 7/100\n",
            "2/2 - 0s - 70ms/step - accuracy: 0.0889 - loss: 3.6843\n",
            "Epoch 8/100\n",
            "2/2 - 0s - 48ms/step - accuracy: 0.0889 - loss: 3.6677\n",
            "Epoch 9/100\n",
            "2/2 - 0s - 72ms/step - accuracy: 0.0889 - loss: 3.6427\n",
            "Epoch 10/100\n",
            "2/2 - 0s - 66ms/step - accuracy: 0.0889 - loss: 3.6061\n",
            "Epoch 11/100\n",
            "2/2 - 0s - 46ms/step - accuracy: 0.1111 - loss: 3.5555\n",
            "Epoch 12/100\n",
            "2/2 - 0s - 46ms/step - accuracy: 0.1111 - loss: 3.5355\n",
            "Epoch 13/100\n",
            "2/2 - 0s - 70ms/step - accuracy: 0.0889 - loss: 3.4945\n",
            "Epoch 14/100\n",
            "2/2 - 0s - 68ms/step - accuracy: 0.0889 - loss: 3.4320\n",
            "Epoch 15/100\n",
            "2/2 - 0s - 79ms/step - accuracy: 0.1111 - loss: 3.3894\n",
            "Epoch 16/100\n",
            "2/2 - 0s - 66ms/step - accuracy: 0.1111 - loss: 3.3163\n",
            "Epoch 17/100\n",
            "2/2 - 0s - 68ms/step - accuracy: 0.0889 - loss: 3.2292\n",
            "Epoch 18/100\n",
            "2/2 - 0s - 48ms/step - accuracy: 0.1111 - loss: 3.1541\n",
            "Epoch 19/100\n",
            "2/2 - 0s - 70ms/step - accuracy: 0.1111 - loss: 3.0591\n",
            "Epoch 20/100\n",
            "2/2 - 0s - 50ms/step - accuracy: 0.1333 - loss: 3.0133\n",
            "Epoch 21/100\n",
            "2/2 - 0s - 66ms/step - accuracy: 0.1333 - loss: 2.8854\n",
            "Epoch 22/100\n",
            "2/2 - 0s - 77ms/step - accuracy: 0.1111 - loss: 2.8438\n",
            "Epoch 23/100\n",
            "2/2 - 0s - 48ms/step - accuracy: 0.1778 - loss: 2.7284\n",
            "Epoch 24/100\n",
            "2/2 - 0s - 68ms/step - accuracy: 0.2222 - loss: 2.6539\n",
            "Epoch 25/100\n",
            "2/2 - 0s - 78ms/step - accuracy: 0.2444 - loss: 2.5620\n",
            "Epoch 26/100\n",
            "2/2 - 0s - 48ms/step - accuracy: 0.2000 - loss: 2.5096\n",
            "Epoch 27/100\n",
            "2/2 - 0s - 72ms/step - accuracy: 0.2444 - loss: 2.4263\n",
            "Epoch 28/100\n",
            "2/2 - 0s - 49ms/step - accuracy: 0.1778 - loss: 2.3818\n",
            "Epoch 29/100\n",
            "2/2 - 0s - 67ms/step - accuracy: 0.1556 - loss: 2.3499\n",
            "Epoch 30/100\n",
            "2/2 - 0s - 76ms/step - accuracy: 0.2667 - loss: 2.2470\n",
            "Epoch 31/100\n",
            "2/2 - 0s - 46ms/step - accuracy: 0.3556 - loss: 2.1913\n",
            "Epoch 32/100\n",
            "2/2 - 0s - 70ms/step - accuracy: 0.3111 - loss: 2.1879\n",
            "Epoch 33/100\n",
            "2/2 - 0s - 103ms/step - accuracy: 0.3333 - loss: 2.1249\n",
            "Epoch 34/100\n",
            "2/2 - 0s - 141ms/step - accuracy: 0.3778 - loss: 2.0430\n",
            "Epoch 35/100\n",
            "2/2 - 0s - 157ms/step - accuracy: 0.4000 - loss: 2.0280\n",
            "Epoch 36/100\n",
            "2/2 - 0s - 80ms/step - accuracy: 0.4222 - loss: 1.9727\n",
            "Epoch 37/100\n",
            "2/2 - 0s - 153ms/step - accuracy: 0.4222 - loss: 1.9087\n",
            "Epoch 38/100\n",
            "2/2 - 0s - 153ms/step - accuracy: 0.4667 - loss: 1.8840\n",
            "Epoch 39/100\n",
            "2/2 - 0s - 86ms/step - accuracy: 0.5556 - loss: 1.8481\n",
            "Epoch 40/100\n",
            "2/2 - 0s - 146ms/step - accuracy: 0.4667 - loss: 1.8034\n",
            "Epoch 41/100\n",
            "2/2 - 0s - 155ms/step - accuracy: 0.4889 - loss: 1.7616\n",
            "Epoch 42/100\n",
            "2/2 - 0s - 92ms/step - accuracy: 0.5111 - loss: 1.7164\n",
            "Epoch 43/100\n",
            "2/2 - 0s - 114ms/step - accuracy: 0.5333 - loss: 1.6905\n",
            "Epoch 44/100\n",
            "2/2 - 0s - 74ms/step - accuracy: 0.5111 - loss: 1.6474\n",
            "Epoch 45/100\n",
            "2/2 - 0s - 48ms/step - accuracy: 0.5556 - loss: 1.5974\n",
            "Epoch 46/100\n",
            "2/2 - 0s - 47ms/step - accuracy: 0.6444 - loss: 1.5640\n",
            "Epoch 47/100\n",
            "2/2 - 0s - 75ms/step - accuracy: 0.5778 - loss: 1.5411\n",
            "Epoch 48/100\n",
            "2/2 - 0s - 47ms/step - accuracy: 0.5556 - loss: 1.5189\n",
            "Epoch 49/100\n",
            "2/2 - 0s - 46ms/step - accuracy: 0.6222 - loss: 1.4845\n",
            "Epoch 50/100\n",
            "2/2 - 0s - 80ms/step - accuracy: 0.6000 - loss: 1.4549\n",
            "Epoch 51/100\n",
            "2/2 - 0s - 57ms/step - accuracy: 0.6222 - loss: 1.4302\n",
            "Epoch 52/100\n",
            "2/2 - 0s - 72ms/step - accuracy: 0.7111 - loss: 1.3933\n",
            "Epoch 53/100\n",
            "2/2 - 0s - 67ms/step - accuracy: 0.7333 - loss: 1.3683\n",
            "Epoch 54/100\n",
            "2/2 - 0s - 50ms/step - accuracy: 0.7556 - loss: 1.3222\n",
            "Epoch 55/100\n",
            "2/2 - 0s - 74ms/step - accuracy: 0.6667 - loss: 1.3027\n",
            "Epoch 56/100\n",
            "2/2 - 0s - 47ms/step - accuracy: 0.7111 - loss: 1.2637\n",
            "Epoch 57/100\n",
            "2/2 - 0s - 71ms/step - accuracy: 0.8000 - loss: 1.2529\n",
            "Epoch 58/100\n",
            "2/2 - 0s - 66ms/step - accuracy: 0.7556 - loss: 1.2201\n",
            "Epoch 59/100\n",
            "2/2 - 0s - 69ms/step - accuracy: 0.8444 - loss: 1.1996\n",
            "Epoch 60/100\n",
            "2/2 - 0s - 44ms/step - accuracy: 0.8667 - loss: 1.1653\n",
            "Epoch 61/100\n",
            "2/2 - 0s - 69ms/step - accuracy: 0.8000 - loss: 1.1471\n",
            "Epoch 62/100\n",
            "2/2 - 0s - 69ms/step - accuracy: 0.8000 - loss: 1.1335\n",
            "Epoch 63/100\n",
            "2/2 - 0s - 69ms/step - accuracy: 0.8667 - loss: 1.0968\n",
            "Epoch 64/100\n",
            "2/2 - 0s - 69ms/step - accuracy: 0.8667 - loss: 1.0689\n",
            "Epoch 65/100\n",
            "2/2 - 0s - 57ms/step - accuracy: 0.9111 - loss: 1.0461\n",
            "Epoch 66/100\n",
            "2/2 - 0s - 58ms/step - accuracy: 0.8667 - loss: 1.0269\n",
            "Epoch 67/100\n",
            "2/2 - 0s - 69ms/step - accuracy: 0.8444 - loss: 1.0073\n",
            "Epoch 68/100\n",
            "2/2 - 0s - 69ms/step - accuracy: 0.8889 - loss: 0.9818\n",
            "Epoch 69/100\n",
            "2/2 - 0s - 46ms/step - accuracy: 0.9111 - loss: 0.9668\n",
            "Epoch 70/100\n",
            "2/2 - 0s - 45ms/step - accuracy: 0.8889 - loss: 0.9433\n",
            "Epoch 71/100\n",
            "2/2 - 0s - 69ms/step - accuracy: 0.9111 - loss: 0.9242\n",
            "Epoch 72/100\n",
            "2/2 - 0s - 69ms/step - accuracy: 0.9111 - loss: 0.9023\n",
            "Epoch 73/100\n",
            "2/2 - 0s - 73ms/step - accuracy: 0.9333 - loss: 0.8892\n",
            "Epoch 74/100\n",
            "2/2 - 0s - 45ms/step - accuracy: 0.9333 - loss: 0.8890\n",
            "Epoch 75/100\n",
            "2/2 - 0s - 49ms/step - accuracy: 0.8667 - loss: 0.8636\n",
            "Epoch 76/100\n",
            "2/2 - 0s - 66ms/step - accuracy: 0.8889 - loss: 0.8720\n",
            "Epoch 77/100\n",
            "2/2 - 0s - 44ms/step - accuracy: 0.8000 - loss: 0.8844\n",
            "Epoch 78/100\n",
            "2/2 - 0s - 47ms/step - accuracy: 0.7111 - loss: 0.9499\n",
            "Epoch 79/100\n",
            "2/2 - 0s - 46ms/step - accuracy: 0.8222 - loss: 0.9083\n",
            "Epoch 80/100\n",
            "2/2 - 0s - 67ms/step - accuracy: 0.9111 - loss: 0.8430\n",
            "Epoch 81/100\n",
            "2/2 - 0s - 47ms/step - accuracy: 0.8222 - loss: 0.8259\n",
            "Epoch 82/100\n",
            "2/2 - 0s - 68ms/step - accuracy: 0.7778 - loss: 0.9062\n",
            "Epoch 83/100\n",
            "2/2 - 0s - 66ms/step - accuracy: 0.8667 - loss: 0.7977\n",
            "Epoch 84/100\n",
            "2/2 - 0s - 69ms/step - accuracy: 0.8444 - loss: 0.7842\n",
            "Epoch 85/100\n",
            "2/2 - 0s - 70ms/step - accuracy: 0.9111 - loss: 0.7468\n",
            "Epoch 86/100\n",
            "2/2 - 0s - 69ms/step - accuracy: 0.9333 - loss: 0.7307\n",
            "Epoch 87/100\n",
            "2/2 - 0s - 77ms/step - accuracy: 0.9778 - loss: 0.7082\n",
            "Epoch 88/100\n",
            "2/2 - 0s - 63ms/step - accuracy: 0.9556 - loss: 0.6985\n",
            "Epoch 89/100\n",
            "2/2 - 0s - 70ms/step - accuracy: 0.9333 - loss: 0.7106\n",
            "Epoch 90/100\n",
            "2/2 - 0s - 69ms/step - accuracy: 0.9556 - loss: 0.6565\n",
            "Epoch 91/100\n",
            "2/2 - 0s - 45ms/step - accuracy: 0.9778 - loss: 0.6730\n",
            "Epoch 92/100\n",
            "2/2 - 0s - 48ms/step - accuracy: 1.0000 - loss: 0.6380\n",
            "Epoch 93/100\n",
            "2/2 - 0s - 66ms/step - accuracy: 0.9778 - loss: 0.6391\n",
            "Epoch 94/100\n",
            "2/2 - 0s - 69ms/step - accuracy: 0.9778 - loss: 0.5974\n",
            "Epoch 95/100\n",
            "2/2 - 0s - 53ms/step - accuracy: 1.0000 - loss: 0.5948\n",
            "Epoch 96/100\n",
            "2/2 - 0s - 64ms/step - accuracy: 1.0000 - loss: 0.5816\n",
            "Epoch 97/100\n",
            "2/2 - 0s - 56ms/step - accuracy: 1.0000 - loss: 0.5626\n",
            "Epoch 98/100\n",
            "2/2 - 0s - 64ms/step - accuracy: 1.0000 - loss: 0.5561\n",
            "Epoch 99/100\n",
            "2/2 - 0s - 72ms/step - accuracy: 0.9778 - loss: 0.5366\n",
            "Epoch 100/100\n",
            "2/2 - 0s - 68ms/step - accuracy: 0.9778 - loss: 0.5296\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e6da7886b30>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict the next word\n",
        "def predict_next_word(model, tokenizer, text_input, max_sequence_len):\n",
        "    token_list = tokenizer.texts_to_sequences([text_input])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict(token_list, verbose=0)\n",
        "    predicted_word_index = np.argmax(predicted, axis=-1)\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted_word_index:\n",
        "            return word\n",
        "\n",
        "# Test the model\n",
        "test_text = \"transforming\"\n",
        "predicted_word = predict_next_word(model, tokenizer, test_text, max_sequence_len)\n",
        "print(f'Predicted next word: {predicted_word}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-12T12:18:01.456119Z",
          "iopub.execute_input": "2024-09-12T12:18:01.456594Z",
          "iopub.status.idle": "2024-09-12T12:18:01.827952Z",
          "shell.execute_reply.started": "2024-09-12T12:18:01.456549Z",
          "shell.execute_reply": "2024-09-12T12:18:01.82686Z"
        },
        "trusted": true,
        "id": "h387_Rx8dF5Q",
        "outputId": "b42c1bcd-ce7c-482f-f572-5eee940b15cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next word: the\n"
          ]
        }
      ]
    }
  ]
}